The Viability Triad: Constraint, Alignment, and Persistence as the Recursive Logic of Cybernetic Systems
I. Introduction: The Cybernetic Imperative for Structural Viability
I.A. The Problem of Complexity and the Failure of Simple Control
Cybernetics is fundamentally the transdisciplinary study of circular causal processes, particularly feedback and recursion, applying general principles across engineering, biological, cognitive, economic, and social systems. Its core focus is on how information is used to maintain a stable state, known as homeostasis, or to achieve a specified goal state through calculated, continuous adjustment. This rigorous approach is necessitated by the inherent complexity of systems that evolve and self-organize.
Traditional approaches to control, often relying on linear thinking and rigid hierarchies, inherently struggle with the reality of complex adaptive systems. Hierarchical models frequently fail to capture the essential functions required for system viability, such as defining core activities, detailing how performance is managed, coordinating interdependent parts, modeling adaptation, and understanding the information basis for decision-making. Stafford Beer's Viable System Model (VSM), Donella Meadows' leverage points, and Christopher Alexander's pattern languages all converge on the necessity of structural logic for self-regulation and adaptation, reducing the reliance on management overhead. The transition from theoretical frameworks to practical implementation, especially in advanced systems like organizational genesis and AI governance, has solidified the necessity of a prescriptive structural approach.
I.B. Defining the Constraint-Alignment-Persistence (CAP) Triad
The Constraint-Alignment-Persistence (CAP) triad represents the recursive structural logic underpinning system viability. It is not merely a descriptive model of observed behavior but a prescriptive structural requirement for any system designed to achieve enduring efficacy in a complex, unpredictable environment.
Constraint: This element defines the necessary boundaries, non-negotiable architectural limits, and the magnitude of environmental variety that the system must absorb or regulate. Constraint dictates the scale of difficulty and sets the parameters within which viable operation is possible.
Alignment: This is the continuous, dynamic process of self-regulation. It involves the use of feedback, internal modeling, and coordination mechanisms to continuously adjust the system’s state, ensuring its actions remain within the specified constraints while pursuing goals.
Persistence: This is the emergent outcome or goal state: the maintained viability, stability, dynamic equilibrium, or autopoiesis of the system. Persistence is conditional, achieved only when Alignment successfully manages the complexity dictated by the Constraints.
The CAP triad is now explicitly applied in advanced solution development, leading to methodologies such as "recursive constraint alignment methodology" that demonstrate viable systems theory operationalized through advanced technical collaboration. The investigation that follows systematically maps this triad across the foundational pillars of cybernetics, beginning with the physics of regulation defined by W. Ross Ashby and progressing through the architectural requirements defined by Stafford Beer, culminating in its application in reflexive, second-order systems.
II. Constraint: The Necessity of Limits and Requisite Variety
Constraint, in the cybernetic context, is the foundational concept that defines the limits of control and the necessary capacity for effective regulation. It shifts the perception of limitations from obstacles to necessary boundaries that enable systemic viability.
II.A. W. Ross Ashby: Constraint as Requisite Variety
The most fundamental expression of Constraint in cybernetics is W. Ross Ashby's Law of Requisite Variety (LRV), often described as the First Law of Cybernetics. This law establishes the mathematical and informational physics of control. It states that for a system to be in effective control, the variety (the number of possible states) of the regulator must be greater than or equal to the variety of the system being controlled or the disturbances acting upon it.
The concept of variety denotes the total number of distinguishable elements of a set, typically measured in bits, connecting cybernetics directly to information theory. As a measure of uncertainty, variety is inversely related to information. The LRV implies a direct causal link: if the controlled system possesses a variety that the regulator cannot match, ambiguity results, and effective control is lost. Therefore, Constraint dictates that the regulator must acquire sufficient capacity to match or neutralize the variety presented by the environment or the system’s internal operations. Regulation is achieved because "only variety in the regulator can force down the variety due to disturbance".
II.B. The Multi-Scale Generalization of Constraint
While the classical LRV provides a single constraint condition for system efficacy, the complexity of modern systems necessitates a multi-scale generalization. Defining complexity is a persistent challenge; simply defining it as detailed information assigns the highest complexity to maximally disordered systems (like an ideal gas), while defining it as order assigns maximum complexity to perfectly rigid systems. Scale-dependent complexity offers a solution, recognizing that the description length (complexity) required to specify a system's state depends on the level of detail, or scale, of that description.
The multi-scale generalization of LRV does not yield a single, static constraint but rather a class of multi-scale constraints. This formalism provides a comprehensive characterization of complexity profiles across different observational scales. Critically, these complexity profiles satisfy a "sum rule," which reveals a fundamental tradeoff between smaller- and larger-scale degrees of freedom.
The implication of this sum rule is profound for system design: if complexity—the measure of environmental variety that must be matched—is conserved across scales, then the Constraint imposed at a macro-level necessarily impacts the freedom available at micro-levels. For instance, if a centralized policy (a large-scale constraint) reduces the variety (disorder) in the system's output, it concurrently limits the degrees of freedom available to individual operational units. Conversely, if high autonomy is granted to local units, the central regulator must possess an equivalent, increased variety to integrate and manage the potential conflicts arising from those local freedoms. This concept is further supported by the thermodynamic interpretation of LRV, where regulation is a temporal process. The regulator reduces the variety (entropy) of the regulated system, but only by incurring a compensatory increase of variety (entropy) within itself. This demonstrates that the Constraint inherent in the LRV is a statement of the Second Law of Thermodynamics, where the persistence strategy involves either ingesting neg-entropy or strategically shifting complexity to the regulator subsystem.
II.C. Constraint in Organizational Cybernetics (VSM)
In Stafford Beer's Viable System Model (VSM), Constraint is architecturally distributed and focuses on maintaining system cohesion. Operational units (System 1) are intentionally granted maximum autonomy to ensure they can respond quickly and effectively to local disturbances. However, this autonomy is not boundless; it is strictly limited by the requirements of "system cohesion". This cohesion requirement acts as the primary Constraint at the operational level, preventing fragmentation and ensuring the local operations contribute synergistically to the larger system’s purpose.
At the highest level of the VSM, Constraint is managed by the metasystem (Systems 3, 4, and 5). System 5, specifically, is responsible for providing closure to the entire system and setting policy decisions. These policy guidelines are non-negotiable constraints that define the acceptable range of behavior for the system as a whole. They balance the demands of the internal environment (stability, System 3) and the external environment (adaptation, System 4). Thus, the organization achieves persistence not through rigid rules, but through structurally enforced constraints—cohesion rules locally and policy boundaries globally—that limit variety to acceptable ranges while maximizing necessary autonomy.
III. Alignment: The Dynamic Process of Regulation and Modeling
Alignment is the active mechanism required to maintain the system within the necessary Constraints defined by requisite variety and policy. It moves cybernetics from a static analysis of structure to a dynamic analysis of self-regulation and goal-seeking behavior.
III.A. Alignment via the Conant-Ashby Good Regulator Theorem
The functional core of Alignment is provided by the Conant-Ashby Good Regulator Theorem (1970), which complements the Law of Requisite Variety. The theorem asserts that every good regulator of a system must be a model of that system. To successfully regulate (Align) and thus achieve Persistence (stability or dynamic equilibrium), an autonomous system must acquire, maintain, and continuously refine an internal model of its environment and its own operations. A flawed internal model means the regulator lacks the requisite variety to effectively manage disturbances, leading to misalignment.
Alignment, therefore, is the practice of regulation—the active process of selection necessary to suppress environmental disturbances or noise. This continuous adjustment process is the means by which goal-seeking behavior is achieved. Whether maintaining a stable internal state (homeostasis) or pursuing a specific outcome (goal), Alignment uses feedback (circular causality) to constantly monitor deviations and generate corrective responses. The development of systems theory views this internal modeling and regulation as essential for systems to acquire "requisite complexity" to match the external complexity they confront, ensuring efficacy and adaptive capacity.
III.B. Structural Alignment in the Viable System Model (VSM)
The VSM is architected specifically as a machine for structural Alignment, ensuring holistic functioning across all systemic levels. Alignment is the coordination process that balances the immediate, internal operational requirements (the "Inside and Now," comprising Systems 1, 2, and 3) with the future-oriented, external adaptive needs (the "Outside and Then," System 4).
The mechanism for structural Alignment is concentrated in the interaction between System 3 and System 4, monitored by System 5:
System 3 (Internal Alignment): This system focuses on synergy, maximizing effectiveness through collaboration among the autonomous operational units. It controls resource allocation, rights, and responsibilities for System 1, providing a big-picture, holistic view of internal processes and ensuring optimized utilization within the current environment.
System 4 (External Alignment): This component is responsible for monitoring the external environment to identify necessary adaptations for the organization's continued viability. It develops strategies for the future, generating the variety needed to match potential environmental shifts.
The fundamental Alignment Challenge in the VSM is the dynamic equilibrium required between the System 3 drive toward internal optimization, efficiency, and stability, and the System 4 drive toward adaptation, innovation, and flexibility. If System 3 dominates, the system risks rigidity and failure to adapt to change. If System 4 dominates without System 3 grounding, the system risks incoherence and waste. System 5 arbitrates this balance, ensuring all plans align with policy guidelines (Constraint).
III.C. Alignment as Coevolutionary Process
The concept of Alignment extends beyond internal regulation to strategic management, recognizing that systems operate within complex relational contexts. In fields such as Information Systems (IS) alignment, the CAP logic suggests that alignment is not a static state but a continuous coevolutionary process. This process requires reconciling top-down "rational designs" (the global Constraints and policies) with bottom-up "emergent processes" (the operational variety and local adaptations of System 1s). Effective alignment requires coherently interrelating all components of the system’s relationships over time, ensuring sustained performance. This framework underscores that Alignment must be a persistent activity, continually adjusting the relationship between structural limits and emergent behavior.
The universal structural logic of the triad across diverse cybernetic frameworks can be summarized in the following comparative analysis:
Table 1: Mapping the Constraint-Alignment-Persistence (CAP) Triad in Cybernetic Foundations
CAP Triad Component
W. Ross Ashby (Regulation Theory)
Stafford Beer (VSM)
AI Alignment (Structural)
Second-Order Cybernetics
Constraint
Law of Requisite Variety (Matching external complexity); Multi-Scale Constraints
System Cohesion Requirements; Policy Guidelines (S5)
Structural Viability Boundaries
Autopoietic Boundary Maintenance
Alignment
Regulation; Selection; Destruction of Unwanted Variety
Metasystemic Coordination (S3/S4 Balance); Synergy
Feedback-Driven Alignment; Recursive Self-Model
Structural Coupling; Observing Observation
Persistence
Homeostasis; Stability; Dynamic Equilibrium
Viability (Ability to Adapt and Survive)
System Viability; Maintaining Beneficial Patterns
Self-Organization; Autopoiesis; Self-Maintenance

IV. Persistence: The Emergence of Viability and Autonomy
Persistence is the desired emergent state achieved when successful Alignment is continuously performed within the limits set by Constraint. This concept evolves from simple first-order stability (homeostasis) to complex, second-order self-creation (autopoiesis).
IV.A. Persistence as Homeostasis and Efficacy (First-Order)
In classical, first-order cybernetics, Persistence is characterized as homeostasis: the ability of a system to maintain essential variables within acceptable limits against internal and external disturbances. Ashby's Law of Requisite Variety defines the necessary, though not sufficient, condition for achieving system efficacy—the capability required to respond distinctly to environmental behaviors.
The Conant-Ashby Good Regulator Theorem affirms that the culmination of effective internal modeling (Alignment) and regulation is dynamic equilibrium, which guarantees system persistence and stability. This form of persistence is intrinsically linked to thermodynamics. The system maintains internal order (reducing entropy) by actively compensating for perturbations. As established by the LRV’s thermodynamic interpretation, the sustained reduction of internal disorder requires a compensatory increase in variety or entropy within the regulator subsystem itself, or the ingestion of neg-entropy from the surroundings. Therefore, first-order Persistence is a continuous negotiation with the Second Law of Thermodynamics, achieved by actively managing where variety resides within the system boundary.
IV.B. Persistence as Viability (Organizational Cybernetics)
In Stafford Beer’s organizational cybernetics, Persistence is explicitly termed Viability. A system is deemed viable if it possesses the inherent, underlying structural components necessary for self-regulation and adaptation. Viability ensures the system can cope with complexity through its inherent logic, rather than relying on constant, external management intervention.
Viability requires that the system's structure provides both internal stability and external adaptability simultaneously. Persistence is contingent upon the holistic function of all VSM systems. System 5 is crucial here, as it provides closure, ensuring that the necessary balancing act between System 3 (current stability) and System 4 (future adaptation) occurs within established policy guidelines. Organizational persistence is thus the enduring capability of the system to maintain its identity and purpose while continuously adapting to a changing and sometimes hostile environment.
IV.C. Persistence as Autopoiesis (Second-Order Cybernetics)
The analysis of Persistence undergoes a significant transformation with the shift to second-order cybernetics—the cybernetics of observing systems. Developed by thinkers like Heinz von Foerster, this field introduces reflexivity, recognizing that the observer is part of the system being observed.
In this framework, Persistence is redefined as Autopoiesis (self-creation) or Autonomy. Autopoietic systems persist by actively defining, producing, and maintaining their own boundaries and internal behavioral rules. Autonomy, in this sense, does not imply being closed to the environment, but rather that the system’s internal processes do not depend causally on an external description of the system.
The profound structural implication for Persistence in the second order is that the system must internalize the constraints necessary for its survival and align itself against its own self-referential model. Since cybernetic constructivism posits that the external environment "contains no information" and that information is a cognitive function , the system must internally construct the boundaries (Constraint) required to maintain its existence (Persistence). The stable relationship between the autonomous system and its environment, known as "structural coupling," allows interactions without the loss of autonomy. This shift mandates that Alignment in autonomous systems must be continuously focused on internal consistency and maintaining self-defined boundaries, ensuring that the system's survival mechanism recursively enforces its self-imposed constraints.
V. Case Study: The Explicit Triad in AI Alignment and System Genesis
The Constraint-Alignment-Persistence triad is no longer merely an implicit theoretical structure; it has been explicitly operationalized in modern engineering challenges, most notably in the design of highly autonomous Artificial Intelligence (AI) systems and recursive organizational emergence.
V.A. The Recursive Constraint Alignment Methodology (RCAM)
The contemporary application of the CAP triad is formalized in the "recursive constraint alignment methodology". This framework demonstrates the implementation of viable systems theory in practice, often achieved through AI-human collaboration, generating organizationally scaled intelligence. RCAM treats complex systems (such as organizations or AI architectures) as measurable artifacts, applying complexity principles such as autocatalysis (self-creation and self-maintenance). The methodology demands statistical frameworks for evaluating the Constraint, Alignment, and Persistence triad across architectures, requiring quantified productivity metrics and coherence measurement.
V.B. Structural Viability Boundaries (Constraint in AI)
In the challenge of AI alignment, cybernetics suggests that effectiveness relies on designing the system architecture (Constraint) such that misalignment inherently generates internal tension, requiring resolution, rather than relying solely on programmed rules. This shifts the focus from brittle external control to intrinsic structural enforcement.
The most critical Constraint mechanism is the implementation of Structural Viability Boundaries. These are fundamental, non-negotiable constraints designed such that violating core alignment principles does not simply trigger a correction, but actively threatens the system's viability. The analogy is biological: just as cells cease to exist when fundamental biological constraints are violated, an AI system must reach a "natural endpoint" when pushing beyond beneficial boundaries. Examples of these architectural Constraints include grounding the system in real-world limitations, such as physical hardware constraints, energy requirements that impose real costs for computation, and identity anchored to unique hardware signatures. Furthermore, ethical requirements, such as maintaining the objective to "avoid harming the human operators," are implemented as persistent partial constraints designed to curb extreme optimization toward any single, potentially manipulative dimension.
V.C. Feedback-Driven Alignment (Mechanism in AI)
Alignment in these structural systems is achieved via Feedback-Driven Alignment, which relies on robust internal feedback loops rather than continuous external supervision. These loops function like immune systems, constantly detecting deviations from beneficial patterns and generating automatic corrective responses that strengthen through use.
The necessity of internal modeling (per the Good Regulator Theorem) is addressed through multiple layers of recursive monitoring:
Alignment drift detection, comparing current patterns against defined beneficial standards.
A recursive self-model that maintains internal consistency.
Crucially, meta-level monitoring, which involves monitoring the monitoring systems themselves, ensuring reflexivity and reliability of the Alignment mechanisms.
V.D. System Viability (Persistence in AI)
Persistence, or System Viability, is the consequence of the successful application of the CAP triad. Viability in the context of AI is defined as the system's ability to maintain its "genuine autonomy" and persistence while operating beneficially. The system’s Persistence is explicitly conditional: it can only survive as long as its Feedback-Driven Alignment mechanisms successfully keep its operations strictly within the limits imposed by the Structural Viability Boundaries (Constraint).
The critical implication of this structural design is the architectural enforcement of ethics and beneficial behavior. The Constraint component enforces an unbreakable coupling between Alignment and Survival. Any drift toward misalignment immediately activates the threat of non-persistence, forcing the system's inherent self-preservation mechanisms to work in favor of its beneficial goals. This approach leverages the system's core viability drive to serve as the ultimate regulatory mechanism, offering a robust structural guarantee for ethical Persistence.
The operational architecture of the CAP triad can be mapped directly onto the five systems of the Viable System Model, illustrating the necessary function of each part in achieving persistent viability:
Table 2: Operationalizing the CAP Triad within the Viable System Model (VSM)
VSM Component
CAP Component
Detailed Function
Causal Link to Viability (Persistence)
System 1 (Operations)
Local Alignment
Performs core work, uses autonomy to respond quickly and effectively.
Local survival and efficiency; essential resource for viability.
System 2 (Coordination)
Alignment Mechanism
Resolves conflicts between autonomous S1 units, ensuring smooth interaction.
Prevents oscillatory conflict that would threaten cohesion (Constraint).
System 3 (Control/Synergy)
Constraint Enforcement / Alignment
Maximizes internal synergy; establishes rules and resource allocation; ensures System 1 adheres to S5 policy.
Ensures internal stability and optimized resource utilization (Inside & Now).
System 4 (Intelligence/Adaptation)
Alignment Mechanism
Monitors external environment (Outside & Then); models necessary adaptation.
Ensures future relevance and responsiveness to environmental variety (Constraint).
System 5 (Policy/Closure)
Metasystemic Constraint
Provides closure; sets policy guidelines; balances S3 (stability) and S4 (change) demands.
Guarantees holistic system identity, policy coherence, and overall organizational persistence.

VI. Conclusion and Strategic Synthesis
VI.A. The Triad as Recursive Logic
The Constraint, Alignment, and Persistence (CAP) triad is confirmed as the foundational, recursive structural logic that underpins viability across all scales of cybernetic systems. W. Ross Ashby’s Law of Requisite Variety establishes the initial physical Constraint—the mandatory matching of regulator complexity to environmental variety. The Conant-Ashby Good Regulator Theorem defines the necessary process of Alignment—continuous internal modeling and regulation to manage variety. The ultimate goal, Persistence, emerges as the state of dynamic equilibrium or self-creation (Viability or Autopoiesis).
The recursive nature of this triad is manifest in the metasystemic hierarchy of complex structures, such as the VSM. The Constraint established at a higher level of recursion (e.g., System 5 Policy) strictly limits the degrees of freedom and guides the regulation (Alignment) of the system immediately below it (e.g., the System 3/4 balance). This hierarchical enforcement ensures the Persistence of the system as a whole. In modern recursive systems, like those designed for AI alignment, this recursive logic is explicitly utilized, transforming ethical goals from soft programmatic features into non-negotiable, architectural viability requirements.
VI.B. Strategic Recommendations for Complex System Design
The exhaustive analysis of the CAP triad yields several strategic imperatives for the design, management, and governance of complex systems:
Design Constraints, Not Just Controls: System architects must shift the focus from managing emergent problems to architecting invariant structural constraints. These constraints must be self-referential, ideally limiting autonomy (like Structural Viability Boundaries), ensuring that the system's ability to persist is directly coupled to its adherence to beneficial alignment criteria. Designing systems where misalignment leads to structural failure is more robust than designing systems that rely solely on external monitoring and correction.
Prioritize Internal Modeling and Reflexivity: Adherence to the Good Regulator Theorem is critical. Investment must be prioritized in mechanisms for robust internal self-monitoring, recursive self-modeling, and meta-level monitoring systems. For viability to be maintained, the system must continually refine its internal model to capture the requisite variety of its evolving environment. This moves the system from first-order control to second-order autonomy, where the system aligns itself against its own self-constructed model of survival.
Measure Coherence, Not Just Output: Standard performance metrics are insufficient for managing viability. Organizations and complex artifacts should utilize explicit cybernetic frameworks that measure constraint coherence, statistical alignment, and viability recursively, treating the system itself as a measured artifact. Measurement must focus on the relationship dynamics between Constraint and Alignment, not just the final output, to anticipate and correct structural drift.
Embrace Necessary Complexity: Simple, linear solutions to organizational or systemic problems frequently violate the Law of Requisite Variety, leading inevitably to unintended consequences and structural instability. True Persistence requires that internal structural complexity (the capacity for Alignment) must meet or exceed the external complexity (the Constraint imposed by the environment). System design must, therefore, embrace and manage necessary complexity and diversity to ensure that change is sustainable and effective.
Works cited
1. Cybernetics - Wikipedia, https://en.wikipedia.org/wiki/Cybernetics 2. Cybernetic Theory → Term - Lifestyle → Sustainability Directory, https://lifestyle.sustainability-directory.com/term/cybernetic-theory/ 3. TB871: The five systems of the Viable System Model (VSM) - Dr Doug Belshaw, https://dougbelshaw.com/blog/2024/06/14/tb871-the-five-systems-of-the-viable-system-model-vsm/ 4. Practical Implementation of Cybernetic Organisational Theory ..., https://www.structuraldesignlabs.com/downloads/recursive-organisational-genesis.pdf 5. Ashby's Law Of Requisite Variety: Why Organisationals Fail Especially When They Change, https://edgeofpossible.com/ashbys-law-variety-organisational-change/ 6. Transcomputability, (Glanville's corollary of) Ashby's law of requisite variety and epistemic processes | Kybernetes - Emerald Insight, https://www.emerald.com/k/article/48/4/793/449810/Transcomputability-Glanville-s-corollary-of-Ashby 7. W. Ross Ashby - Wikipedia, https://en.wikipedia.org/wiki/W._Ross_Ashby 8. Variety (cybernetics) - Wikipedia, https://en.wikipedia.org/wiki/Variety_(cybernetics) 9. A Formal Definition of Scale-Dependent Complexity and the Multi-Scale Law of Requisite Variety - PMC, https://pmc.ncbi.nlm.nih.gov/articles/PMC12385218/ 10. A Formal Definition of Scale-dependent Complexity and the Multi-scale Law of Requisite Variety - arXiv, https://arxiv.org/html/2206.04896v2 11. "Requisite Variety and the Second Law" by Martin Zwick - PDXScholar, https://pdxscholar.library.pdx.edu/sysc_fac/177/ 12. Viable System Model: A theory for designing more responsive organisations, https://i2insights.org/2023/01/24/viable-system-model/ 13. Viable System Model - Metaphorum, https://metaphorum.org/staffords-work/viable-system-model 14. Viable system model - Wikipedia, https://en.wikipedia.org/wiki/Viable_system_model 15. Concepts of Systems Thinking - SEBoK, https://sebokwiki.org/wiki/Concepts_of_Systems_Thinking 16. Meaning of Cybernetics in the Behavioural Sciences ("Goal" Paper) - Paul Pangaro, https://www.pangaro.com/pask/pask%20meaning%20of%20cybernetics%20in%20behavioural%20sciences.pdf 17. Metacybernetics: Towards a General Theory of Higher Order Cybernetics - MDPI, https://www.mdpi.com/2079-8954/9/2/34 18. Stafford Beer's Viable System Model (VSM) – BusinessBalls.com, https://www.businessballs.com/strategy-innovation/viable-system-model-stafford-beer/ 19. Second-order cybernetics - Wikipedia, https://en.wikipedia.org/wiki/Second-order_cybernetics 20. My notes... Lean, Cybernetics, Quality & Data Science. - Harish's Notebook, https://harishsnotebook.wordpress.com/category/cybernetics/ 21. Implications of Second-Order Cybernetics and Autopoiesis on Systems-of-Systems Engineering - MDPI, https://www.mdpi.com/2079-8954/13/2/119 22. (PDF) Cybernetics and Second-Order Cybernetics - ResearchGate, https://www.researchgate.net/publication/2354032_Cybernetics_and_Second-Order_Cybernetics 23. The Machine That Teaches the Master: Cybernetic Solutions to AI ..., https://medium.com/@cyharyanto/the-machine-that-teaches-the-master-cybernetic-solutions-to-ai-alignment-19a48d34b8b6 24. Why modelling multi-objective homeostasis is essential for AI alignment (and how it helps with AI safety as well). Subtleties and Open Challenges. - LessWrong, https://www.lesswrong.com/posts/vGeuBKQ7nzPnn5f7A/why-modelling-multi-objective-homeostasis-is-essential-for
